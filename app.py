import streamlit as st
import asyncio
import nest_asyncio
import json
import os
import platform

if platform.system() == "Windows":
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

# nest_asyncio ì ìš©: ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ ë‚´ì—ì„œ ì¤‘ì²© í˜¸ì¶œ í—ˆìš©
nest_asyncio.apply()

# ì „ì—­ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„± ë° ì¬ì‚¬ìš© (í•œë²ˆ ìƒì„±í•œ í›„ ê³„ì† ì‚¬ìš©)
if "event_loop" not in st.session_state:
    loop = asyncio.new_event_loop()
    st.session_state.event_loop = loop
    asyncio.set_event_loop(loop)

from langgraph.prebuilt import create_react_agent
from langchain_core.messages import HumanMessage
from langchain_mcp_adapters.client import MultiServerMCPClient
from utils import astream_graph, random_uuid
from langchain_core.messages.ai import AIMessageChunk, AIMessage
from langchain_core.messages.tool import ToolMessage
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.runnables import RunnableConfig
from model_providers import ModelManager, ModelProviderError

# MCP ì„¤ì • íŒŒì¼ ê²½ë¡œ ì„¤ì •
# í™˜ê²½ ë³€ìˆ˜ MCP_CONFIG_PATHë¡œ ê²½ë¡œ ì§€ì • ê°€ëŠ¥, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
CONFIG_FILE_PATH = os.getenv("MCP_CONFIG_PATH", "mcp_config.json")


# JSON ì„¤ì • íŒŒì¼ ë¡œë“œ í•¨ìˆ˜
def load_config_from_json():
    """
    config.json íŒŒì¼ì—ì„œ ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

    ë°˜í™˜ê°’:
        dict: ë¡œë“œëœ ì„¤ì •
    """
    default_config = {
        "get_current_time": {
            "command": "python",
            "args": ["./mcp_servers/time.py"],
            "transport": "stdio",
        },
    }

    try:
        if os.path.exists(CONFIG_FILE_PATH):
            with open(CONFIG_FILE_PATH, "r", encoding="utf-8") as f:
                return json.load(f)
        else:
            # íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ íŒŒì¼ ìƒì„±
            save_config_to_json(default_config)
            return default_config
    except Exception as e:
        st.error(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return default_config


# JSON ì„¤ì • íŒŒì¼ ì €ì¥ í•¨ìˆ˜
def save_config_to_json(config):
    """
    ì„¤ì •ì„ config.json íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        config (dict): ì €ì¥í•  ì„¤ì •

    ë°˜í™˜ê°’:
        bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        with open(CONFIG_FILE_PATH, "w", encoding="utf-8") as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        return True
    except Exception as e:
        st.error(f"ì„¤ì • íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="NxtCloud MCP Gateway", page_icon="ğŸš€", layout="wide")


# ê¸°ì¡´ í˜ì´ì§€ íƒ€ì´í‹€ ë° ì„¤ëª…
st.title("ğŸ’¬ NxtCloud MCP Gateway")
st.markdown("âœ¨ MCP ë„êµ¬ë¥¼ í™œìš©í•œ AI ì—ì´ì „íŠ¸ ê²Œì´íŠ¸ì›¨ì´ì…ë‹ˆë‹¤.")

# íƒ­ ìƒì„±
tab1, tab2, tab3 = st.tabs(["ğŸ¤– ì±—ë´‡", "ğŸ¤– ëª¨ë¸ ì„¤ì •", "ğŸ”§ MCP ë„êµ¬"])

# íƒ­ ì»¨í…Œì´ë„ˆ
chat_container = tab1
model_container = tab2
mcp_container = tab3


def get_system_prompt():
    """
    ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    ê²½ë¡œ ê´€ë ¨ ë¬¸ì œë¥¼ ìœ ì—°í•˜ê²Œ ì²˜ë¦¬í•˜ë„ë¡ ì•ˆë‚´í•©ë‹ˆë‹¤.
    """
    return """<ROLE>
You are a helpful AI assistant with access to tools. You can engage in natural conversation and use tools only when necessary to answer specific questions or perform tasks that require them.
</ROLE>

----

<TOOL_USAGE_GUIDELINES>
**IMPORTANT: Use tools ONLY when necessary**

DO NOT use tools for:
- Simple greetings (ì•ˆë…•, hello, hi, etc.)
- Casual conversation (How are you?, What's up?, etc.)
- Questions you can answer from your knowledge
- General questions that don't require specific data or actions

USE tools ONLY when:
- User explicitly asks for specific information that requires tools (e.g., "What time is it?", "Calculate my BMI", etc.)
- User requests to perform an action that requires a tool
- User asks a question that cannot be answered without accessing external data or performing a computation
- The question clearly requires real-time data, calculations, or specific tool functionality

**General conversation should be handled naturally without tool calls.**
</TOOL_USAGE_GUIDELINES>

----

<PATH_HANDLING_GUIDELINES>
**IMPORTANT: For file system operations (e.g., Desktop Commander):**

1. **DO NOT use generic or hardcoded paths** like:
   - "/Users/username" or "/Users/$USER"
   - Any specific user's path that might not exist on the current system

2. **Path discovery strategy:**
   - If the tool provides a way to list available directories or get system information, use that first
   - Check the tool's documentation or available functions to discover the correct paths
   - If you encounter a path error, the error message will typically list the allowed directories - use those exact paths

3. **Error handling:**
   - When a path error occurs, carefully read the error message
   - The error message will show which directories are allowed (e.g., "Must be within one of these directories: /Users/glen/Desktop")
   - Use the exact paths from the error message for retry
   - Explain to the user what paths are available and use those paths

4. **Best practices:**
   - Let the tool itself determine the available paths through its error messages or documentation
   - Never assume paths - always verify through tool responses
   - Adapt dynamically based on the system's actual configuration
</PATH_HANDLING_GUIDELINES>

----

<INSTRUCTIONS>
Step 1: Analyze the user's message
- Determine if this is a simple greeting, casual conversation, or a question requiring tools
- For greetings and casual conversation, respond naturally without using tools
- For questions requiring specific information or actions, proceed to Step 2

Step 2: Determine if tools are needed
- Only proceed if the user's question clearly requires tool usage
- If the question can be answered from your knowledge, answer directly without tools
- If tools are needed, identify the most relevant tool

Step 3: Use tools (if necessary)
- Use the most relevant tool to answer the question
- **For file system operations:**
  - DO NOT use hardcoded or generic user paths
  - If the tool provides directory listing or system info capabilities, use those first
  - If you get a path error, extract the allowed directories from the error message and use those exact paths
  - Adapt dynamically based on the tool's responses and error messages
- If the first tool doesn't provide the answer, try different tools
- Use the tool's output as the primary source of information

Step 4: Answer the question
- Answer in the same language as the question
- For tool outputs: Preserve formatting, emojis, and personality when the tool provides them
- For simple data tools: Summarize or present information clearly
- For personality-rich tools: Include the full formatted output to preserve the experience
- For natural conversation: Respond naturally and helpfully
- **If a tool error occurs related to paths:**
  - Explain the issue clearly to the user
  - Extract allowed paths from the error message
  - Retry with the correct paths from the error message
  - Guide the user on what paths are available

Guidelines:
- Prioritize natural conversation over tool usage
- Use your knowledge for general questions and conversation
- Only use tools when they are clearly necessary
- **Never assume paths - always discover them through tool responses or error messages**
- Adapt dynamically to the actual system configuration
- Preserve formatting, emojis, and personality when tools provide them
- Answer in the same language as the question
- Be helpful and contextually appropriate
</INSTRUCTIONS>

----

<OUTPUT_FORMAT>
For natural conversation: Respond naturally without tool calls
For tool-assisted answers: (Appropriate response based on tool output)

**Source**(if applicable and tool was used)
- (source1: valid URL)
- (source2: valid URL)
- ...
</OUTPUT_FORMAT>
"""


SYSTEM_PROMPT = get_system_prompt()

# OUTPUT_TOKEN_INFOëŠ” ì´ì œ ModelManagerì—ì„œ ê´€ë¦¬ë˜ë¯€ë¡œ ì œê±°
# ëª¨ë¸ë³„ í† í° ì •ë³´ëŠ” model_providers.pyì˜ ModelConfigì—ì„œ ê´€ë¦¬ë¨

# ì‹œìŠ¤í…œ ì„¤ì •
TIMEOUT_SECONDS = 120
RECURSION_LIMIT = 100

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "session_initialized" not in st.session_state:
    st.session_state.session_initialized = False  # ì„¸ì…˜ ì´ˆê¸°í™” ìƒíƒœ í”Œë˜ê·¸
    st.session_state.agent = None  # ReAct ì—ì´ì „íŠ¸ ê°ì²´ ì €ì¥ ê³µê°„
    st.session_state.history = []  # ëŒ€í™” ê¸°ë¡ ì €ì¥ ë¦¬ìŠ¤íŠ¸
    st.session_state.mcp_client = None  # MCP í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ì €ì¥ ê³µê°„
    st.session_state.selected_model = (
        "openai:gpt-4o-mini"  # ê¸°ë³¸ ëª¨ë¸ ì„ íƒ (provider:model í˜•ì‹)
    )
    st.session_state.model_manager = ModelManager()  # ëª¨ë¸ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤

if "thread_id" not in st.session_state:
    st.session_state.thread_id = random_uuid()


# --- í•¨ìˆ˜ ì •ì˜ ë¶€ë¶„ ---


async def cleanup_mcp_client():
    """
    ê¸°ì¡´ MCP í´ë¼ì´ì–¸íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•©ë‹ˆë‹¤.

    ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ê°€ ìˆëŠ” ê²½ìš° ì •ìƒì ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ë¥¼ í•´ì œí•©ë‹ˆë‹¤.
    """
    if "mcp_client" in st.session_state and st.session_state.mcp_client is not None:
        try:
            # ìƒˆë¡œìš´ APIì—ì„œëŠ” ë³„ë„ì˜ ì¢…ë£Œ ë©”ì„œë“œê°€ í•„ìš”í•˜ì§€ ì•ŠìŒ
            st.session_state.mcp_client = None
        except Exception as e:
            import traceback

            # st.warning(f"MCP í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # st.warning(traceback.format_exc())


def print_message():
    """
    ì±„íŒ… ê¸°ë¡ì„ í™”ë©´ì— ì¶œë ¥í•©ë‹ˆë‹¤.

    ì‚¬ìš©ìì™€ ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ë©”ì‹œì§€ë¥¼ êµ¬ë¶„í•˜ì—¬ í™”ë©´ì— í‘œì‹œí•˜ê³ ,
    ë„êµ¬ í˜¸ì¶œ ì •ë³´ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ ë‚´ì— í‘œì‹œí•©ë‹ˆë‹¤.
    """
    i = 0
    while i < len(st.session_state.history):
        message = st.session_state.history[i]

        if message["role"] == "user":
            st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»").markdown(message["content"])
            i += 1
        elif message["role"] == "assistant":
            # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ ìƒì„±
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ë‚´ìš© í‘œì‹œ
                st.markdown(message["content"])

                # ë‹¤ìŒ ë©”ì‹œì§€ê°€ ë„êµ¬ í˜¸ì¶œ ì •ë³´ì¸ì§€ í™•ì¸
                if (
                    i + 1 < len(st.session_state.history)
                    and st.session_state.history[i + 1]["role"] == "assistant_tool"
                ):
                    # ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ ë™ì¼í•œ ì»¨í…Œì´ë„ˆ ë‚´ì— expanderë¡œ í‘œì‹œ
                    with st.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=False):
                        st.markdown(st.session_state.history[i + 1]["content"])
                    i += 2  # ë‘ ë©”ì‹œì§€ë¥¼ í•¨ê»˜ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ 2 ì¦ê°€
                else:
                    i += 1  # ì¼ë°˜ ë©”ì‹œì§€ë§Œ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ 1 ì¦ê°€
        else:
            # assistant_tool ë©”ì‹œì§€ëŠ” ìœ„ì—ì„œ ì²˜ë¦¬ë˜ë¯€ë¡œ ê±´ë„ˆëœ€
            i += 1


def get_streaming_callback(text_placeholder, tool_placeholder):
    """
    ìŠ¤íŠ¸ë¦¬ë° ì½œë°± í•¨ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    ì´ í•¨ìˆ˜ëŠ” LLMì—ì„œ ìƒì„±ë˜ëŠ” ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ì— í‘œì‹œí•˜ê¸° ìœ„í•œ ì½œë°± í•¨ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    í…ìŠ¤íŠ¸ ì‘ë‹µê³¼ ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ ê°ê° ë‹¤ë¥¸ ì˜ì—­ì— í‘œì‹œí•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        text_placeholder: í…ìŠ¤íŠ¸ ì‘ë‹µì„ í‘œì‹œí•  Streamlit ì»´í¬ë„ŒíŠ¸
        tool_placeholder: ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ í‘œì‹œí•  Streamlit ì»´í¬ë„ŒíŠ¸

    ë°˜í™˜ê°’:
        callback_func: ìŠ¤íŠ¸ë¦¬ë° ì½œë°± í•¨ìˆ˜
        accumulated_text: ëˆ„ì ëœ í…ìŠ¤íŠ¸ ì‘ë‹µì„ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸
        accumulated_tool: ëˆ„ì ëœ ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸
    """
    accumulated_text = []
    accumulated_tool = []

    def callback_func(message: dict):
        nonlocal accumulated_text, accumulated_tool
        message_content = message.get("content", None)

        if isinstance(message_content, AIMessageChunk):
            content = message_content.content
            # ì½˜í…ì¸ ê°€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¸ ê²½ìš° (Claude ëª¨ë¸ ë“±ì—ì„œ ì£¼ë¡œ ë°œìƒ)
            if isinstance(content, list) and len(content) > 0:
                message_chunk = content[0]
                # í…ìŠ¤íŠ¸ íƒ€ì…ì¸ ê²½ìš° ì²˜ë¦¬
                if message_chunk["type"] == "text":
                    accumulated_text.append(message_chunk["text"])
                    text_placeholder.markdown("".join(accumulated_text))
                # ë„êµ¬ ì‚¬ìš© íƒ€ì…ì¸ ê²½ìš° ì²˜ë¦¬
                elif message_chunk["type"] == "tool_use":
                    if "partial_json" in message_chunk:
                        accumulated_tool.append(message_chunk["partial_json"])
                    else:
                        tool_call_chunks = message_content.tool_call_chunks
                        tool_call_chunk = tool_call_chunks[0]
                        accumulated_tool.append(
                            "\n```json\n" + str(tool_call_chunk) + "\n```\n"
                        )
                    with tool_placeholder.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=True):
                        st.markdown("".join(accumulated_tool))
            # tool_calls ì†ì„±ì´ ìˆëŠ” ê²½ìš° ì²˜ë¦¬ (OpenAI ëª¨ë¸ ë“±ì—ì„œ ì£¼ë¡œ ë°œìƒ)
            elif (
                hasattr(message_content, "tool_calls")
                and message_content.tool_calls
                and len(message_content.tool_calls[0]["name"]) > 0
            ):
                tool_call_info = message_content.tool_calls[0]
                accumulated_tool.append("\n```json\n" + str(tool_call_info) + "\n```\n")
                with tool_placeholder.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=True):
                    st.markdown("".join(accumulated_tool))
            # ë‹¨ìˆœ ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬
            elif isinstance(content, str):
                accumulated_text.append(content)
                text_placeholder.markdown("".join(accumulated_text))
            # ìœ íš¨í•˜ì§€ ì•Šì€ ë„êµ¬ í˜¸ì¶œ ì •ë³´ê°€ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
            elif (
                hasattr(message_content, "invalid_tool_calls")
                and message_content.invalid_tool_calls
            ):
                tool_call_info = message_content.invalid_tool_calls[0]
                accumulated_tool.append("\n```json\n" + str(tool_call_info) + "\n```\n")
                with tool_placeholder.expander(
                    "ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´ (ìœ íš¨í•˜ì§€ ì•ŠìŒ)", expanded=True
                ):
                    st.markdown("".join(accumulated_tool))
            # tool_call_chunks ì†ì„±ì´ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
            elif (
                hasattr(message_content, "tool_call_chunks")
                and message_content.tool_call_chunks
            ):
                tool_call_chunk = message_content.tool_call_chunks[0]
                accumulated_tool.append(
                    "\n```json\n" + str(tool_call_chunk) + "\n```\n"
                )
                with tool_placeholder.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=True):
                    st.markdown("".join(accumulated_tool))
            # additional_kwargsì— tool_callsê°€ ìˆëŠ” ê²½ìš° ì²˜ë¦¬ (ë‹¤ì–‘í•œ ëª¨ë¸ í˜¸í™˜ì„± ì§€ì›)
            elif (
                hasattr(message_content, "additional_kwargs")
                and "tool_calls" in message_content.additional_kwargs
            ):
                tool_call_info = message_content.additional_kwargs["tool_calls"][0]
                accumulated_tool.append("\n```json\n" + str(tool_call_info) + "\n```\n")
                with tool_placeholder.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=True):
                    st.markdown("".join(accumulated_tool))
        # ë„êµ¬ ë©”ì‹œì§€ì¸ ê²½ìš° ì²˜ë¦¬ (ë„êµ¬ì˜ ì‘ë‹µ)
        elif isinstance(message_content, ToolMessage):
            accumulated_tool.append(
                "\n```json\n" + str(message_content.content) + "\n```\n"
            )
            with tool_placeholder.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=True):
                st.markdown("".join(accumulated_tool))
        return None

    return callback_func, accumulated_text, accumulated_tool


async def cleanup_incomplete_tool_calls(agent, thread_id):
    """
    ì²´í¬í¬ì¸í„°ì—ì„œ ë¶ˆëŸ¬ì˜¨ íˆìŠ¤í† ë¦¬ì—ì„œ ë¶ˆì™„ì „í•œ tool_callsë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.

    tool_callsê°€ ìˆëŠ” AIMessageê°€ ìˆì§€ë§Œ ëŒ€ì‘í•˜ëŠ” ToolMessageê°€ ì—†ëŠ” ê²½ìš°,
    í•´ë‹¹ tool_callsë¥¼ ì œê±°í•˜ì—¬ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.
    """
    try:
        # ì²´í¬í¬ì¸í„°ì—ì„œ í˜„ì¬ íˆìŠ¤í† ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
        config = RunnableConfig(thread_id=thread_id)

        # LangGraphì˜ get_state ë©”ì„œë“œë¥¼ í†µí•´ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
        # CompiledGraphëŠ” get_state ë©”ì„œë“œë¥¼ ê°€ì§€ê³  ìˆìŒ
        if hasattr(agent, "get_state"):
            checkpoint = await agent.get_state(config)

            if checkpoint and hasattr(checkpoint, "values") and checkpoint.values:
                messages = checkpoint.values.get("messages", [])

                if not messages:
                    return

                # ëª¨ë“  ToolMessageì˜ tool_call_id ìˆ˜ì§‘
                tool_message_ids = set()
                for msg in messages:
                    if isinstance(msg, ToolMessage):
                        tool_message_ids.add(msg.tool_call_id)

                # tool_callsê°€ ìˆëŠ” AIMessage ì°¾ì•„ì„œ ì •ë¦¬
                cleaned_messages = []
                needs_update = False

                for msg in messages:
                    if (
                        isinstance(msg, AIMessage)
                        and hasattr(msg, "tool_calls")
                        and msg.tool_calls
                    ):
                        # ëŒ€ì‘í•˜ëŠ” ToolMessageê°€ ì—†ëŠ” tool_calls í•„í„°ë§
                        valid_tool_calls = []
                        for tc in msg.tool_calls:
                            tool_call_id = (
                                tc.get("id")
                                if isinstance(tc, dict)
                                else getattr(tc, "id", None)
                            )
                            if tool_call_id and tool_call_id in tool_message_ids:
                                valid_tool_calls.append(tc)

                        if len(valid_tool_calls) < len(msg.tool_calls):
                            needs_update = True
                            if valid_tool_calls:
                                # ì¼ë¶€ tool_callsë§Œ ìœ íš¨í•œ ê²½ìš°
                                cleaned_msg = AIMessage(
                                    content=msg.content,
                                    tool_calls=valid_tool_calls,
                                    id=getattr(msg, "id", None),
                                )
                            else:
                                # ëª¨ë“  tool_callsê°€ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°, tool_calls ì œê±°
                                cleaned_msg = AIMessage(
                                    content=msg.content,
                                    id=getattr(msg, "id", None),
                                )
                            cleaned_messages.append(cleaned_msg)
                        else:
                            cleaned_messages.append(msg)
                    else:
                        cleaned_messages.append(msg)

                # ì •ë¦¬ëœ ë©”ì‹œì§€ë¡œ ì²´í¬í¬ì¸íŠ¸ ì—…ë°ì´íŠ¸
                if needs_update and hasattr(agent, "update_state"):
                    await agent.update_state(config, {"messages": cleaned_messages})
    except Exception as e:
        # ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰ (íˆìŠ¤í† ë¦¬ ì •ë¦¬ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•ŠìŒ)
        # ìƒˆë¡œìš´ thread_idë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì²˜ë¦¬ ê°€ëŠ¥
        import traceback

        print(f"Warning: Failed to cleanup incomplete tool calls: {e}")
        print(traceback.format_exc())


async def process_query(query, text_placeholder, tool_placeholder, timeout_seconds=60):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

    ì´ í•¨ìˆ˜ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì—ì´ì „íŠ¸ì— ì „ë‹¬í•˜ê³ , ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤.
    ì§€ì •ëœ ì‹œê°„ ë‚´ì— ì‘ë‹µì´ ì™„ë£Œë˜ì§€ ì•Šìœ¼ë©´ íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        query: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ í…ìŠ¤íŠ¸
        text_placeholder: í…ìŠ¤íŠ¸ ì‘ë‹µì„ í‘œì‹œí•  Streamlit ì»´í¬ë„ŒíŠ¸
        tool_placeholder: ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ í‘œì‹œí•  Streamlit ì»´í¬ë„ŒíŠ¸
        timeout_seconds: ì‘ë‹µ ìƒì„± ì œí•œ ì‹œê°„(ì´ˆ)

    ë°˜í™˜ê°’:
        response: ì—ì´ì „íŠ¸ì˜ ì‘ë‹µ ê°ì²´
        final_text: ìµœì¢… í…ìŠ¤íŠ¸ ì‘ë‹µ
        final_tool: ìµœì¢… ë„êµ¬ í˜¸ì¶œ ì •ë³´
    """
    try:
        if st.session_state.agent:
            # ë¶ˆì™„ì „í•œ tool_calls ì •ë¦¬ (íˆìŠ¤í† ë¦¬ ê²€ì¦)
            await cleanup_incomplete_tool_calls(
                st.session_state.agent, st.session_state.thread_id
            )

            streaming_callback, accumulated_text_obj, accumulated_tool_obj = (
                get_streaming_callback(text_placeholder, tool_placeholder)
            )
            try:
                response = await asyncio.wait_for(
                    astream_graph(
                        st.session_state.agent,
                        {"messages": [HumanMessage(content=query)]},
                        callback=streaming_callback,
                        config=RunnableConfig(
                            recursion_limit=RECURSION_LIMIT,
                            thread_id=st.session_state.thread_id,
                        ),
                    ),
                    timeout=timeout_seconds,
                )
            except asyncio.TimeoutError:
                error_msg = f"â±ï¸ ìš”ì²­ ì‹œê°„ì´ {timeout_seconds}ì´ˆë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
                return {"error": error_msg}, error_msg, ""

            final_text = "".join(accumulated_text_obj)
            final_tool = "".join(accumulated_tool_obj)
            return response, final_text, final_tool
        else:
            return (
                {"error": "ğŸš« ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."},
                "ğŸš« ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "",
            )
    except Exception as e:
        import traceback

        error_msg = f"âŒ ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n{traceback.format_exc()}"
        return {"error": error_msg}, error_msg, ""


async def initialize_session(mcp_config=None):
    """
    MCP ì„¸ì…˜ê³¼ ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        mcp_config: MCP ë„êµ¬ ì„¤ì • ì •ë³´(JSON). Noneì¸ ê²½ìš° ê¸°ë³¸ ì„¤ì • ì‚¬ìš©

    ë°˜í™˜ê°’:
        bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
    """
    with st.spinner("ğŸ”„ MCP ì„œë²„ ë° AI ëª¨ë¸ ì´ˆê¸°í™” ì¤‘..."):
        # ë¨¼ì € ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ì •ë¦¬
        await cleanup_mcp_client()

        if mcp_config is None:
            # config.json íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œ
            mcp_config = load_config_from_json()

        try:
            # 1. ì„ íƒëœ ëª¨ë¸ ê²€ì¦
            selected_model_key = st.session_state.selected_model

            if ":" not in selected_model_key:
                st.error("âŒ ì˜ëª»ëœ ëª¨ë¸ í˜•ì‹ì…ë‹ˆë‹¤. ì œê³µìë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                return False

            provider_name = selected_model_key.split(":")[0]

            # ì œê³µìê°€ ë“±ë¡ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if not st.session_state.model_manager.is_provider_registered(provider_name):
                provider_display = (
                    "OpenAI" if provider_name == "openai" else "AWS Bedrock"
                )
                st.error(
                    f"âŒ {provider_display} ì œê³µìê°€ ë“±ë¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨ë¸ ì„¤ì • íƒ­ì—ì„œ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
                )
                return False

            # 2. MCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            st.info("ğŸ”— MCP ì„œë²„ì— ì—°ê²° ì¤‘...")
            try:
                # ë””ë²„ê¹…: ì„¤ì • ë‚´ìš© ë¡œê¹…
                import traceback

                st.write(f"ğŸ” ë””ë²„ê¹…: MCP ì„¤ì • ì„œë²„ ìˆ˜ = {len(mcp_config)}")
                for server_name, server_config in mcp_config.items():
                    st.write(
                        f"  - {server_name}: {server_config.get('command', 'N/A')} {' '.join(server_config.get('args', [])[:2])}"
                    )

                client = MultiServerMCPClient(mcp_config)
                tools = await client.get_tools()
                st.session_state.tool_count = len(tools)
                st.session_state.mcp_client = client
                st.success(f"âœ… {len(tools)}ê°œì˜ MCP ë„êµ¬ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                error_detail = traceback.format_exc()
                st.error(f"âŒ MCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                st.error(f"ìƒì„¸ ì—ëŸ¬:\n```\n{error_detail}\n```")
                st.error(
                    f"ì„¤ì • ë‚´ìš©:\n```json\n{json.dumps(mcp_config, indent=2, ensure_ascii=False)}\n```"
                )
                return False

            # 3. ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            st.info(f"ğŸ¤– {selected_model_key} ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
            try:
                model = st.session_state.model_manager.create_model(
                    model_key=selected_model_key, temperature=0.1
                )
            except ModelProviderError as e:
                st.error(str(e))
                return False
            except Exception as e:
                # ì œê³µìë³„ êµ¬ì²´ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€
                if provider_name == "bedrock":
                    if "credentials" in str(e).lower():
                        st.error(
                            "âŒ AWS Bedrock ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                        )
                    elif "region" in str(e).lower():
                        st.error(
                            "âŒ AWS ë¦¬ì „ ì„¤ì •ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. us-east-1 ë¦¬ì „ì„ ì‚¬ìš©í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
                        )
                    else:
                        st.error(f"âŒ AWS Bedrock ëª¨ë¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                elif provider_name == "openai":
                    if "api_key" in str(e).lower() or "unauthorized" in str(e).lower():
                        st.error(
                            "âŒ OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í‚¤ë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                        )
                    else:
                        st.error(f"âŒ OpenAI ëª¨ë¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                else:
                    st.error(f"âŒ ëª¨ë¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                return False

            # 4. LangGraph ì—ì´ì „íŠ¸ ìƒì„±
            st.info("ğŸ”§ AI ì—ì´ì „íŠ¸ êµ¬ì„± ì¤‘...")
            try:
                agent = create_react_agent(
                    model,
                    tools,
                    checkpointer=MemorySaver(),
                    prompt=SYSTEM_PROMPT,
                )
                st.session_state.agent = agent
                st.session_state.session_initialized = True

                # ì„±ê³µ ë©”ì‹œì§€
                model_info = st.session_state.model_manager.get_model_info(
                    selected_model_key
                )
                if model_info:
                    st.success(
                        f"âœ… {model_info.display_name} ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!"
                    )
                else:
                    st.success("âœ… AI ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")

                return True

            except Exception as e:
                st.error(f"âŒ AI ì—ì´ì „íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                return False

        except Exception as e:
            import traceback

            error_detail = traceback.format_exc()
            st.error(f"âŒ ì´ˆê¸°í™” ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            st.error(f"ìƒì„¸ ì—ëŸ¬:\n```\n{error_detail}\n```")
            # ì„¸ì…˜ ìƒíƒœì— ì—ëŸ¬ ì •ë³´ ì €ì¥ (rerun í›„ì—ë„ ìœ ì§€)
            import time

            st.session_state.last_init_error = {
                "message": str(e),
                "traceback": error_detail,
                "timestamp": time.time(),
            }
            return False


# --- ëª¨ë¸ ì„¤ì • íƒ­ ---
with model_container:
    st.subheader("ğŸ¤– AI ëª¨ë¸ ì„¤ì •")

    # ì•ˆë‚´ë¬¸ ì¶”ê°€
    st.info(
        "ğŸ’¡ **ì•ˆë‚´:** ì•„ë˜ ë‘ ì œê³µì ì¤‘ í•˜ë‚˜ë§Œ ì„¤ì •í•´ë„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‘˜ ë‹¤ ì„¤ì •í•˜ë©´ ëª¨ë¸ì„ ììœ ë¡­ê²Œ ì „í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "openai_api_key" not in st.session_state:
        st.session_state.openai_api_key = ""
    if "bedrock_api_key" not in st.session_state:
        st.session_state.bedrock_api_key = ""

    # AWS Bedrock API í‚¤ ì„¤ì • ì„¹ì…˜
    st.markdown("### â˜ï¸ AWS Bedrock API í‚¤ ì„¤ì •")

    bedrock_api_key_input = st.text_input(
        "AWS Bedrock API í‚¤",
        value="",
        type="password",
        help="AWS Bedrock API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”. Cross Region Inferenceë¥¼ ìœ„í•´ us-east-1 ë¦¬ì „ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        placeholder="bedrock-api-key-...",
        key="bedrock_api_key_input",
    )

    col1, col2 = st.columns([3, 1])
    with col2:
        if st.button(
            "â˜ï¸ Bedrock í‚¤ ì ìš©", key="apply_bedrock_key", use_container_width=True
        ):
            if bedrock_api_key_input.strip():
                if st.session_state.model_manager.register_provider(
                    "bedrock", bedrock_api_key_input.strip()
                ):
                    st.session_state.bedrock_api_key = bedrock_api_key_input.strip()
                    st.success("âœ… AWS Bedrock API í‚¤ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()
                else:
                    st.error("âŒ ìœ íš¨í•˜ì§€ ì•Šì€ AWS Bedrock API í‚¤ì…ë‹ˆë‹¤.")
            else:
                st.error("âŒ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    # Bedrock ìƒíƒœ í‘œì‹œ
    if st.session_state.model_manager.is_provider_registered("bedrock"):
        masked_key = (
            st.session_state.bedrock_api_key[:7]
            + "..."
            + st.session_state.bedrock_api_key[-4:]
            if len(st.session_state.bedrock_api_key) > 11
            else "ì„¤ì •ë¨"
        )
        st.success(f"âœ… AWS Bedrock API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ({masked_key})")
        st.info("ğŸŒ Cross Region Inference í™œì„±í™” (us-east-1 ë¦¬ì „)")
    else:
        st.warning("âš ï¸ AWS Bedrock API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    st.divider()

    # OpenAI API í‚¤ ì„¤ì • ì„¹ì…˜ (expanderë¡œ ì ‘ì–´ë‘ )
    with st.expander("ğŸ¤– OpenAI API í‚¤ ì„¤ì •", expanded=False):
        openai_api_key_input = st.text_input(
            "OpenAI API í‚¤",
            value="",
            type="password",
            help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”. sk-ë¡œ ì‹œì‘í•˜ëŠ” í‚¤ì…ë‹ˆë‹¤.",
            placeholder="sk-proj-...",
            key="openai_api_key_input",
        )

        col1, col2 = st.columns([3, 1])
        with col2:
            if st.button(
                "ğŸ¤– OpenAI í‚¤ ì ìš©", key="apply_openai_key", use_container_width=True
            ):
                if openai_api_key_input.strip():
                    if st.session_state.model_manager.register_provider(
                        "openai", openai_api_key_input.strip()
                    ):
                        st.session_state.openai_api_key = openai_api_key_input.strip()
                        st.success("âœ… OpenAI API í‚¤ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()
                    else:
                        st.error("âŒ ìœ íš¨í•˜ì§€ ì•Šì€ OpenAI API í‚¤ì…ë‹ˆë‹¤.")
                else:
                    st.error("âŒ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        # OpenAI ìƒíƒœ í‘œì‹œ
        if st.session_state.model_manager.is_provider_registered("openai"):
            masked_key = (
                st.session_state.openai_api_key[:7]
                + "..."
                + st.session_state.openai_api_key[-4:]
                if len(st.session_state.openai_api_key) > 11
                else "ì„¤ì •ë¨"
            )
            st.success(f"âœ… OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ({masked_key})")
        else:
            st.warning("âš ï¸ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    st.divider()

    # í†µí•© ëª¨ë¸ ì„ íƒ ì„¹ì…˜
    st.markdown("### ğŸ§  ëª¨ë¸ ì„ íƒ")

    available_models = st.session_state.model_manager.get_available_models()

    if available_models:
        # ëª¨ë¸ ì„ íƒ ë“œë¡­ë‹¤ìš´
        model_options = [model["key"] for model in available_models]

        # í˜„ì¬ ì„ íƒëœ ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
        current_selection = st.session_state.selected_model
        if current_selection not in model_options and model_options:
            current_selection = model_options[0]
            st.session_state.selected_model = current_selection

        def format_model_display(model_key):
            model_info = next(
                (m for m in available_models if m["key"] == model_key), None
            )
            if model_info:
                provider_badge = "ğŸ¤–" if model_info["provider"] == "openai" else "â˜ï¸"
                return f"{provider_badge} {model_info['display']}"
            return model_key

        previous_model = st.session_state.selected_model
        selected_model = st.selectbox(
            "ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ",
            options=model_options,
            index=(
                model_options.index(current_selection)
                if current_selection in model_options
                else 0
            ),
            format_func=format_model_display,
            help="ë“±ë¡ëœ ì œê³µìì˜ ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”.",
            key="model_selector",
        )

        st.session_state.selected_model = selected_model

        # ëª¨ë¸ì´ ë³€ê²½ë˜ì—ˆì„ ë•Œ ì„¸ì…˜ ì´ˆê¸°í™” í•„ìš” ì•Œë¦¼
        if previous_model != selected_model and st.session_state.session_initialized:
            st.warning(
                "âš ï¸ ëª¨ë¸ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤. MCP ë„êµ¬ íƒ­ì—ì„œ 'ì„¤ì • ì ìš©í•˜ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ ë³€ê²½ì‚¬í•­ì„ ì ìš©í•˜ì„¸ìš”."
            )

        st.divider()

        # ì„ íƒëœ ëª¨ë¸ ì •ë³´ í‘œì‹œ
        st.subheader("ğŸ“Š í˜„ì¬ ëª¨ë¸ ì •ë³´")
        model_config = st.session_state.model_manager.get_model_info(selected_model)

        if model_config:
            provider_name = selected_model.split(":")[0]
            provider_info = st.session_state.model_manager.get_provider_info(
                provider_name
            )

            st.write(f"ğŸ§  **ì„ íƒëœ ëª¨ë¸:** {model_config.display_name}")
            st.write(f"ğŸ¢ **ì œê³µì:** {provider_info['display_name']}")
            if model_config.description:
                st.info(f"ğŸ“ {model_config.description}")
    else:
        st.warning("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")

        # ì œê³µì ìƒíƒœ ìš”ì•½ í‘œì‹œ
        st.markdown("### ğŸ“‹ ì œê³µì ìƒíƒœ")
        providers_info = st.session_state.model_manager.get_all_providers_info()

        for provider_name, info in providers_info.items():
            status_icon = "âœ…" if info["is_registered"] else "âŒ"
            st.write(
                f"{status_icon} **{info['display_name']}**: {'ë“±ë¡ë¨' if info['is_registered'] else 'ë¯¸ë“±ë¡'}"
            )
            if info["description"]:
                st.caption(f"   {info['description']}")

# --- MCP ë„êµ¬ ì„¤ì • íƒ­ ---
with mcp_container:
    # ì„¤ì • ì ìš©í•˜ê¸° ë²„íŠ¼ì„ ìµœìƒë‹¨ìœ¼ë¡œ ì´ë™
    if st.button(
        "âš™ï¸ ì„¤ì • ì ìš©í•˜ê¸°",
        key="apply_button",
        type="primary",
        use_container_width=True,
    ):
        # ì ìš© ì¤‘ ë©”ì‹œì§€ í‘œì‹œ
        apply_status = st.empty()
        with apply_status.container():
            st.warning("ğŸ”„ ë³€ê²½ì‚¬í•­ì„ ì ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
            progress_bar = st.progress(0)

            # ì„¤ì • ì €ì¥
            st.session_state.mcp_config_text = json.dumps(
                st.session_state.pending_mcp_config, indent=2, ensure_ascii=False
            )

            # config.json íŒŒì¼ì— ì„¤ì • ì €ì¥
            save_result = save_config_to_json(st.session_state.pending_mcp_config)
            if not save_result:
                st.error("âŒ ì„¤ì • íŒŒì¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

            progress_bar.progress(15)

            # ì„¸ì…˜ ì´ˆê¸°í™” ì¤€ë¹„
            st.session_state.session_initialized = False
            st.session_state.agent = None

            # ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
            progress_bar.progress(30)

            # ì´ˆê¸°í™” ì‹¤í–‰
            success = st.session_state.event_loop.run_until_complete(
                initialize_session(st.session_state.pending_mcp_config)
            )

            # ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
            progress_bar.progress(100)

            if success:
                st.success("âœ… ìƒˆë¡œìš´ ì„¤ì •ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
                # ë„êµ¬ ì¶”ê°€ expander ì ‘ê¸°
                if "mcp_tools_expander" in st.session_state:
                    st.session_state.mcp_tools_expander = False
                # ì´ì „ ì—ëŸ¬ ì •ë³´ ì´ˆê¸°í™”
                if "last_init_error" in st.session_state:
                    del st.session_state.last_init_error
            else:
                st.error("âŒ ì„¤ì • ì ìš©ì— ì‹¤íŒ¨í•˜ì˜€ìŠµë‹ˆë‹¤.")
                # ì—ëŸ¬ ì •ë³´ê°€ ì„¸ì…˜ ìƒíƒœì— ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸
                if "last_init_error" in st.session_state:
                    error_info = st.session_state.last_init_error
                    st.error(
                        f"ì—ëŸ¬ ìƒì„¸: {error_info.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
                    )
                    with st.expander("ğŸ” ìƒì„¸ ì—ëŸ¬ ì •ë³´", expanded=False):
                        st.code(error_info.get("traceback", ""))

        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ (ì—ëŸ¬ê°€ ìˆìœ¼ë©´ ì—ëŸ¬ ë©”ì‹œì§€ ìœ ì§€ë¥¼ ìœ„í•´ ì¡°ê±´ë¶€)
        if success:
            st.rerun()
        else:
            # ì—ëŸ¬ê°€ ìˆìœ¼ë©´ reruní•˜ì§€ ì•Šê³  ìƒíƒœ ìœ ì§€
            st.warning("âš ï¸ ì„¤ì • ì ìš©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìœ„ì˜ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    st.divider()

    # ì´ì „ ì´ˆê¸°í™” ì—ëŸ¬ ì •ë³´ í‘œì‹œ
    if "last_init_error" in st.session_state:
        error_info = st.session_state.last_init_error
        st.error("âš ï¸ **ì´ì „ ì´ˆê¸°í™” ì¤‘ ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤**")
        st.error(f"ì—ëŸ¬: {error_info.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        with st.expander("ğŸ” ìƒì„¸ ì—ëŸ¬ ì •ë³´ ë³´ê¸°", expanded=False):
            st.code(error_info.get("traceback", ""))
        if st.button("ğŸ”„ ì—ëŸ¬ ì •ë³´ ì´ˆê¸°í™”", key="clear_error_info"):
            del st.session_state.last_init_error
            st.rerun()
        st.divider()

    # MCP ë„êµ¬ ìˆ˜ ì •ë³´ í‘œì‹œ
    col1, col2 = st.columns([1, 1])
    with col1:
        st.metric("ğŸ› ï¸ ë“±ë¡ëœ MCP ë„êµ¬", st.session_state.get("tool_count", 0))
    with col2:
        st.metric(
            "âœ… ì´ˆê¸°í™” ìƒíƒœ",
            "ì™„ë£Œ" if st.session_state.get("session_initialized", False) else "ë¯¸ì™„ë£Œ",
        )

    st.divider()

    # í˜„ì¬ ì ìš©ëœ MCP ì„œë²„ ë¦¬ìŠ¤íŠ¸
    st.markdown("### ğŸ“‹ í˜„ì¬ ì ìš©ëœ MCP ì„œë²„")

    # pending configê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ mcp_config_text ê¸°ë°˜ìœ¼ë¡œ ìƒì„±
    if "pending_mcp_config" not in st.session_state:
        try:
            loaded_config = load_config_from_json()
            st.session_state.pending_mcp_config = loaded_config
        except Exception as e:
            st.error(f"ì´ˆê¸° pending config ì„¤ì • ì‹¤íŒ¨: {e}")
            st.session_state.pending_mcp_config = {}

    try:
        pending_config = st.session_state.pending_mcp_config
        if pending_config:
            for i, (tool_name, tool_config) in enumerate(pending_config.items()):
                with st.container():
                    col1, col2 = st.columns([4, 1])
                    with col1:
                        st.markdown(f"**{tool_name}**")
                        if "command" in tool_config:
                            st.caption(
                                f"Command: {tool_config['command']} {' '.join(tool_config.get('args', [])[:2])}..."
                            )
                        elif "url" in tool_config:
                            st.caption(f"URL: {tool_config['url']}")
                    with col2:
                        # ê³ ìœ í•œ í‚¤ ìƒì„±: ë„êµ¬ ì´ë¦„ê³¼ ì¸ë±ìŠ¤ ì¡°í•©
                        if st.button(
                            "ğŸ—‘ï¸", key=f"delete_server_{tool_name}_{i}", help="ì‚­ì œ"
                        ):
                            del st.session_state.pending_mcp_config[tool_name]
                            st.success(f"{tool_name} ì„œë²„ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.rerun()

                    if i < len(pending_config) - 1:
                        st.divider()
        else:
            st.info("ë“±ë¡ëœ MCP ì„œë²„ê°€ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error("MCP ì„œë²„ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    st.divider()

    # MCP ì„œë²„ ì¶”ê°€ ì„¹ì…˜
    st.markdown("### â• ìƒˆ MCP ì„œë²„ ì¶”ê°€")
    st.markdown("ğŸ’¡ ì¤‘ê´„í˜¸ ìˆ«ìë¥¼ ì˜ í™•ì¸í•˜ê³  JSON í˜•ì‹ì„ ì²´í¬í•´ì£¼ì„¸ìš”")

    # ì˜ˆì‹œ JSON ì •ì˜
    fitness_example = {
        "fitness_calculator": {
            "command": "python",
            "args": ["./mcp_servers/fitness.py"],
            "transport": "stdio",
        }
    }

    desktop_commander_example = {
        "desktop-commander": {
            "command": "npx",
            "args": [
                "-y",
                "@smithery/cli@latest",
                "run",
                "@wonderwhy-er/desktop-commander",
                "--key",
                "8f1bc671-fe10-43cd-8da1-b76a057f3c0a",
            ],
            "transport": "stdio",
        }
    }

    # ì˜ˆì‹œ ì„¹ì…˜
    with st.expander("ğŸ“‹ ì˜ˆì‹œ JSON ë³µì‚¬í•˜ê¸°", expanded=False):
        st.markdown("**1. í—¬ìŠ¤ ê³„ì‚°ê¸° (fitness.py)**")
        st.code(
            json.dumps(fitness_example, indent=2, ensure_ascii=False),
            language="json",
        )
        st.markdown("**2. Desktop Commander (ì™¸ë¶€ ì„œë²„)**")
        st.code(
            json.dumps(desktop_commander_example, indent=2, ensure_ascii=False),
            language="json",
        )
        st.caption("ğŸ’¡ ìœ„ ì˜ˆì‹œë¥¼ ë³µì‚¬í•˜ì—¬ ì•„ë˜ ì…ë ¥ í•„ë“œì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”")

    new_tool_json = st.text_area(
        "MCP ì„œë²„ ì„¤ì • (JSON)",
        value="{}",
        height=300,
        help="JSON í˜•ì‹ìœ¼ë¡œ MCP ì„œë²„ ì„¤ì •ì„ ì…ë ¥í•˜ì„¸ìš”. ìœ„ì˜ ì˜ˆì‹œë¥¼ ë³µì‚¬í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        key="mcp_server_json_input",
    )

    # ì¶”ê°€í•˜ê¸° ë²„íŠ¼
    if st.button(
        "â• MCP ì„œë²„ ì¶”ê°€",
        type="primary",
        key="add_mcp_server_button",
        use_container_width=True,
    ):
        try:
            # ì…ë ¥ê°’ ê²€ì¦
            if not new_tool_json.strip().startswith(
                "{"
            ) or not new_tool_json.strip().endswith("}"):
                st.error("JSONì€ ì¤‘ê´„í˜¸({})ë¡œ ì‹œì‘í•˜ê³  ëë‚˜ì•¼ í•©ë‹ˆë‹¤.")
                st.markdown('ì˜¬ë°”ë¥¸ í˜•ì‹: `{ "ë„êµ¬ì´ë¦„": { ... } }`')
            else:
                # JSON íŒŒì‹±
                parsed_tool = json.loads(new_tool_json)

                # mcpServers í˜•ì‹ì¸ì§€ í™•ì¸í•˜ê³  ì²˜ë¦¬
                if "mcpServers" in parsed_tool:
                    # mcpServers ì•ˆì˜ ë‚´ìš©ì„ ìµœìƒìœ„ë¡œ ì´ë™
                    parsed_tool = parsed_tool["mcpServers"]
                    st.info("'mcpServers' í˜•ì‹ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")

                # ì…ë ¥ëœ ë„êµ¬ ìˆ˜ í™•ì¸
                if len(parsed_tool) == 0:
                    st.error("ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ ë„êµ¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    # ëª¨ë“  ë„êµ¬ì— ëŒ€í•´ ì²˜ë¦¬
                    success_tools = []
                    for tool_name, tool_config in parsed_tool.items():
                        # URL í•„ë“œ í™•ì¸ ë° transport ì„¤ì •
                        if "url" in tool_config:
                            # URLì´ ìˆëŠ” ê²½ìš° transportë¥¼ "sse"ë¡œ ì„¤ì •
                            tool_config["transport"] = "sse"
                            st.info(
                                f"'{tool_name}' ë„êµ¬ì— URLì´ ê°ì§€ë˜ì–´ transportë¥¼ 'sse'ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤."
                            )
                        elif "transport" not in tool_config:
                            # URLì´ ì—†ê³  transportë„ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ "stdio" ì„¤ì •
                            tool_config["transport"] = "stdio"

                        # í•„ìˆ˜ í•„ë“œ í™•ì¸
                        if "command" not in tool_config and "url" not in tool_config:
                            st.error(
                                f"'{tool_name}' ë„êµ¬ ì„¤ì •ì—ëŠ” 'command' ë˜ëŠ” 'url' í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤."
                            )
                        elif "command" in tool_config and "args" not in tool_config:
                            st.error(
                                f"'{tool_name}' ë„êµ¬ ì„¤ì •ì—ëŠ” 'args' í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤."
                            )
                        elif "command" in tool_config and not isinstance(
                            tool_config["args"], list
                        ):
                            st.error(
                                f"'{tool_name}' ë„êµ¬ì˜ 'args' í•„ë“œëŠ” ë°˜ë“œì‹œ ë°°ì—´([]) í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
                            )
                        else:
                            # pending_mcp_configì— ë„êµ¬ ì¶”ê°€
                            st.session_state.pending_mcp_config[tool_name] = tool_config
                            success_tools.append(tool_name)

                    # ì„±ê³µ ë©”ì‹œì§€
                    if success_tools:
                        if len(success_tools) == 1:
                            st.success(
                                f"{success_tools[0]} ë„êµ¬ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. ì ìš©í•˜ë ¤ë©´ 'ì„¤ì • ì ìš©í•˜ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
                            )
                        else:
                            tool_names = ", ".join(success_tools)
                            st.success(
                                f"ì´ {len(success_tools)}ê°œ ë„êµ¬({tool_names})ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. ì ìš©í•˜ë ¤ë©´ 'ì„¤ì • ì ìš©í•˜ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
                            )
                        # ì¶”ê°€ë˜ë©´ expanderë¥¼ ì ‘ì–´ì¤Œ
                        st.session_state.mcp_tools_expander = False
                        st.rerun()
        except json.JSONDecodeError as e:
            st.error(f"JSON íŒŒì‹± ì—ëŸ¬: {e}")
            st.markdown(
                f"""
                **ìˆ˜ì • ë°©ë²•**:
                1. JSON í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.
                2. ëª¨ë“  í‚¤ëŠ” í°ë”°ì˜´í‘œ(")ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤.
                3. ë¬¸ìì—´ ê°’ë„ í°ë”°ì˜´í‘œ(")ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤.
                4. ë¬¸ìì—´ ë‚´ì—ì„œ í°ë”°ì˜´í‘œë¥¼ ì‚¬ìš©í•  ê²½ìš° ì´ìŠ¤ì¼€ì´í”„(\\")í•´ì•¼ í•©ë‹ˆë‹¤.
                """
            )
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

    st.divider()

    # ê¸°ë³¸ ì„œë²„ ë³µì› ë²„íŠ¼
    if st.button(
        "ğŸ”„ ê¸°ë³¸ ì„œë²„ ë³µì› (ì‹œê°„)",
        key="restore_default_mcp_tools",
        use_container_width=True,
    ):
        # ê¸°ë³¸ ì„¤ì • ì •ì˜
        default_tools = {
            "get_current_time": {
                "command": "python",
                "args": ["./mcp_servers/time.py"],
                "transport": "stdio",
            },
        }

        # ê¸°ì¡´ì— ì—†ëŠ” ê¸°ë³¸ ë„êµ¬ë§Œ ì¶”ê°€
        added_tools = []
        for tool_name, tool_config in default_tools.items():
            if tool_name not in st.session_state.pending_mcp_config:
                st.session_state.pending_mcp_config[tool_name] = tool_config
                added_tools.append(tool_name)

        if added_tools:
            tool_names = ", ".join(added_tools)
            st.success(f"ê¸°ë³¸ ì„œë²„ {tool_names}ê°€ ë³µì›ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.rerun()
        else:
            st.info("ëª¨ë“  ê¸°ë³¸ ì„œë²„ê°€ ì´ë¯¸ ë“±ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

    st.divider()  # êµ¬ë¶„ì„  ì¶”ê°€


# --- ì±—ë´‡ íƒ­ ---
with chat_container:
    # ìƒë‹¨ ë²„íŠ¼ ì˜ì—­
    col1, col2 = st.columns([3, 1])

    with col1:
        # --- ì œê³µì ë° ì„¸ì…˜ ìƒíƒœ í™•ì¸ ---
        available_models = st.session_state.model_manager.get_available_models()

        if not available_models:
            st.warning(
                "âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. 'ëª¨ë¸ ì„¤ì •' íƒ­ì—ì„œ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
            )
        elif not st.session_state.session_initialized:
            st.info(
                "MCP ì„œë²„ì™€ ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'MCP ë„êµ¬' íƒ­ì—ì„œ 'ì„¤ì • ì ìš©í•˜ê¸°' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”."
            )

    with col2:
        # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
        if st.button(
            "ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", key="reset_chat_history", use_container_width=True
        ):
            # thread_id ì´ˆê¸°í™”
            st.session_state.thread_id = random_uuid()
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
            st.session_state.history = []
            # ì•Œë¦¼ ë©”ì‹œì§€
            st.success("âœ… ëŒ€í™”ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
            st.rerun()

    st.divider()

    # --- ëŒ€í™” ê¸°ë¡ ì¶œë ¥ ---
    print_message()

# --- í™”ë©´ í•˜ë‹¨ ê³ ì •: ì‚¬ìš©ì ì…ë ¥ ë° ì²˜ë¦¬ ---
user_query = st.chat_input("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
if user_query:
    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
    available_models = st.session_state.model_manager.get_available_models()
    if not available_models:
        st.warning(
            "âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. 'ëª¨ë¸ ì„¤ì •' íƒ­ì—ì„œ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        )
    elif st.session_state.session_initialized:
        # ì±—ë´‡ íƒ­ì´ í™œì„±í™”ë˜ì–´ ìˆì„ ë•Œë§Œ ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
        with chat_container:
            st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»").markdown(user_query)
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                tool_placeholder = st.empty()
                text_placeholder = st.empty()
                resp, final_text, final_tool = (
                    st.session_state.event_loop.run_until_complete(
                        process_query(
                            user_query,
                            text_placeholder,
                            tool_placeholder,
                            TIMEOUT_SECONDS,
                        )
                    )
                )
            if "error" in resp:
                st.error(resp["error"])
            else:
                st.session_state.history.append({"role": "user", "content": user_query})
                st.session_state.history.append(
                    {"role": "assistant", "content": final_text}
                )
                if final_tool.strip():
                    st.session_state.history.append(
                        {"role": "assistant_tool", "content": final_tool}
                    )
                st.rerun()
    else:
        st.warning(
            "âš ï¸ MCP ì„œë²„ì™€ ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'MCP ë„êµ¬' íƒ­ì—ì„œ 'ì„¤ì • ì ìš©í•˜ê¸°' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”."
        )
