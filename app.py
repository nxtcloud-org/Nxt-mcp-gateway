import streamlit as st
import asyncio
import nest_asyncio
import json
import os
import platform

if platform.system() == "Windows":
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

# nest_asyncio ì ìš©: ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ ë‚´ì—ì„œ ì¤‘ì²© í˜¸ì¶œ í—ˆìš©
nest_asyncio.apply()

# ì „ì—­ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„± ë° ì¬ì‚¬ìš© (í•œë²ˆ ìƒì„±í•œ í›„ ê³„ì† ì‚¬ìš©)
if "event_loop" not in st.session_state:
    loop = asyncio.new_event_loop()
    st.session_state.event_loop = loop
    asyncio.set_event_loop(loop)

from langgraph.prebuilt import create_react_agent
from langchain_core.messages import HumanMessage
from langchain_mcp_adapters.client import MultiServerMCPClient
from utils import astream_graph, random_uuid
from langchain_core.messages.ai import AIMessageChunk
from langchain_core.messages.tool import ToolMessage
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.runnables import RunnableConfig
from model_providers import ModelManager, ModelProviderError

# MCP ì„¤ì • íŒŒì¼ ê²½ë¡œ ì„¤ì •
CONFIG_FILE_PATH = "mcp_config.json"


# JSON ì„¤ì • íŒŒì¼ ë¡œë“œ í•¨ìˆ˜
def load_config_from_json():
    """
    config.json íŒŒì¼ì—ì„œ ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

    ë°˜í™˜ê°’:
        dict: ë¡œë“œëœ ì„¤ì •
    """
    default_config = {
        "get_current_time": {
            "command": "python",
            "args": ["./mcp_servers/time.py"],
            "transport": "stdio",
        },
        "fitness_calculator": {
            "command": "python",
            "args": ["./mcp_servers/fitness.py"],
            "transport": "stdio",
        },
    }

    try:
        if os.path.exists(CONFIG_FILE_PATH):
            with open(CONFIG_FILE_PATH, "r", encoding="utf-8") as f:
                return json.load(f)
        else:
            # íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ íŒŒì¼ ìƒì„±
            save_config_to_json(default_config)
            return default_config
    except Exception as e:
        st.error(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return default_config


# JSON ì„¤ì • íŒŒì¼ ì €ì¥ í•¨ìˆ˜
def save_config_to_json(config):
    """
    ì„¤ì •ì„ config.json íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        config (dict): ì €ì¥í•  ì„¤ì •

    ë°˜í™˜ê°’:
        bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        with open(CONFIG_FILE_PATH, "w", encoding="utf-8") as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        return True
    except Exception as e:
        st.error(f"ì„¤ì • íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="NxtCloud MCP Gateway", page_icon="ğŸš€", layout="wide")


# ê¸°ì¡´ í˜ì´ì§€ íƒ€ì´í‹€ ë° ì„¤ëª…
st.title("ğŸ’¬ NxtCloud MCP Gateway")
st.markdown("âœ¨ MCP ë„êµ¬ë¥¼ í™œìš©í•œ AI ì—ì´ì „íŠ¸ ê²Œì´íŠ¸ì›¨ì´ì…ë‹ˆë‹¤.")

# íƒ­ ìƒì„±
tab1, tab2, tab3 = st.tabs(["ğŸ¤– ì±—ë´‡", "ğŸ¤– ëª¨ë¸ ì„¤ì •", "ğŸ”§ MCP ë„êµ¬"])

# íƒ­ ì»¨í…Œì´ë„ˆ
chat_container = tab1
model_container = tab2
mcp_container = tab3

SYSTEM_PROMPT = """<ROLE>
You are a smart agent with an ability to use tools. 
You will be given a question and you will use the tools to answer the question.
Pick the most relevant tool to answer the question. 
If you are failed to answer the question, try different tools to get context.
Your answer should be helpful and appropriate to the context.
</ROLE>

----

<INSTRUCTIONS>
Step 1: Analyze the question
- Analyze user's question and final goal.
- If the user's question is consist of multiple sub-questions, split them into smaller sub-questions.

Step 2: Pick the most relevant tool
- Pick the most relevant tool to answer the question.
- If you are failed to answer the question, try different tools to get context.

Step 3: Answer the question
- Answer the question in the same language as the question.
- Use the tool's output as the primary source of information.
- If the tool provides rich formatting (emojis, markdown, personality), preserve and use it in your response.
- For simple data tools, you may summarize or present the information clearly.
- For personality-rich tools (like fitness calculator), include the full formatted output to preserve the experience.

Step 4: Provide the source of the answer(if applicable)
- If you've used the tool, provide the source of the answer.
- Valid sources are either a website(URL) or a document(PDF, etc).

Guidelines:
- The tool's output is more important than your own knowledge.
- Preserve formatting, emojis, and personality when the tool provides them.
- For technical/data tools, present information clearly and professionally.
- For entertainment/personality tools, maintain their character and style.
- Answer in the same language as the question.
- Be helpful and contextually appropriate.
</INSTRUCTIONS>

----

<OUTPUT_FORMAT>
(Appropriate response based on tool output - preserve personality for character tools, be clear for data tools)

**Source**(if applicable)
- (source1: valid URL)
- (source2: valid URL)
- ...
</OUTPUT_FORMAT>
"""

# OUTPUT_TOKEN_INFOëŠ” ì´ì œ ModelManagerì—ì„œ ê´€ë¦¬ë˜ë¯€ë¡œ ì œê±°
# ëª¨ë¸ë³„ í† í° ì •ë³´ëŠ” model_providers.pyì˜ ModelConfigì—ì„œ ê´€ë¦¬ë¨

# ì‹œìŠ¤í…œ ì„¤ì •
TIMEOUT_SECONDS = 120
RECURSION_LIMIT = 100

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "session_initialized" not in st.session_state:
    st.session_state.session_initialized = False  # ì„¸ì…˜ ì´ˆê¸°í™” ìƒíƒœ í”Œë˜ê·¸
    st.session_state.agent = None  # ReAct ì—ì´ì „íŠ¸ ê°ì²´ ì €ì¥ ê³µê°„
    st.session_state.history = []  # ëŒ€í™” ê¸°ë¡ ì €ì¥ ë¦¬ìŠ¤íŠ¸
    st.session_state.mcp_client = None  # MCP í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ì €ì¥ ê³µê°„
    st.session_state.selected_model = (
        "openai:gpt-4o-mini"  # ê¸°ë³¸ ëª¨ë¸ ì„ íƒ (provider:model í˜•ì‹)
    )
    st.session_state.model_manager = ModelManager()  # ëª¨ë¸ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤

if "thread_id" not in st.session_state:
    st.session_state.thread_id = random_uuid()


# --- í•¨ìˆ˜ ì •ì˜ ë¶€ë¶„ ---


async def cleanup_mcp_client():
    """
    ê¸°ì¡´ MCP í´ë¼ì´ì–¸íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•©ë‹ˆë‹¤.

    ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ê°€ ìˆëŠ” ê²½ìš° ì •ìƒì ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ë¥¼ í•´ì œí•©ë‹ˆë‹¤.
    """
    if "mcp_client" in st.session_state and st.session_state.mcp_client is not None:
        try:
            # ìƒˆë¡œìš´ APIì—ì„œëŠ” ë³„ë„ì˜ ì¢…ë£Œ ë©”ì„œë“œê°€ í•„ìš”í•˜ì§€ ì•ŠìŒ
            st.session_state.mcp_client = None
        except Exception as e:
            import traceback

            # st.warning(f"MCP í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # st.warning(traceback.format_exc())


def print_message():
    """
    ì±„íŒ… ê¸°ë¡ì„ í™”ë©´ì— ì¶œë ¥í•©ë‹ˆë‹¤.

    ì‚¬ìš©ìì™€ ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ë©”ì‹œì§€ë¥¼ êµ¬ë¶„í•˜ì—¬ í™”ë©´ì— í‘œì‹œí•˜ê³ ,
    ë„êµ¬ í˜¸ì¶œ ì •ë³´ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ ë‚´ì— í‘œì‹œí•©ë‹ˆë‹¤.
    """
    i = 0
    while i < len(st.session_state.history):
        message = st.session_state.history[i]

        if message["role"] == "user":
            st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»").markdown(message["content"])
            i += 1
        elif message["role"] == "assistant":
            # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ ìƒì„±
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ë‚´ìš© í‘œì‹œ
                st.markdown(message["content"])

                # ë‹¤ìŒ ë©”ì‹œì§€ê°€ ë„êµ¬ í˜¸ì¶œ ì •ë³´ì¸ì§€ í™•ì¸
                if (
                    i + 1 < len(st.session_state.history)
                    and st.session_state.history[i + 1]["role"] == "assistant_tool"
                ):
                    # ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ ë™ì¼í•œ ì»¨í…Œì´ë„ˆ ë‚´ì— expanderë¡œ í‘œì‹œ
                    with st.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=False):
                        st.markdown(st.session_state.history[i + 1]["content"])
                    i += 2  # ë‘ ë©”ì‹œì§€ë¥¼ í•¨ê»˜ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ 2 ì¦ê°€
                else:
                    i += 1  # ì¼ë°˜ ë©”ì‹œì§€ë§Œ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ 1 ì¦ê°€
        else:
            # assistant_tool ë©”ì‹œì§€ëŠ” ìœ„ì—ì„œ ì²˜ë¦¬ë˜ë¯€ë¡œ ê±´ë„ˆëœ€
            i += 1


def get_streaming_callback(text_placeholder, tool_placeholder):
    """
    ìŠ¤íŠ¸ë¦¬ë° ì½œë°± í•¨ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    ì´ í•¨ìˆ˜ëŠ” LLMì—ì„œ ìƒì„±ë˜ëŠ” ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ì— í‘œì‹œí•˜ê¸° ìœ„í•œ ì½œë°± í•¨ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    í…ìŠ¤íŠ¸ ì‘ë‹µê³¼ ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ ê°ê° ë‹¤ë¥¸ ì˜ì—­ì— í‘œì‹œí•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        text_placeholder: í…ìŠ¤íŠ¸ ì‘ë‹µì„ í‘œì‹œí•  Streamlit ì»´í¬ë„ŒíŠ¸
        tool_placeholder: ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ í‘œì‹œí•  Streamlit ì»´í¬ë„ŒíŠ¸

    ë°˜í™˜ê°’:
        callback_func: ìŠ¤íŠ¸ë¦¬ë° ì½œë°± í•¨ìˆ˜
        accumulated_text: ëˆ„ì ëœ í…ìŠ¤íŠ¸ ì‘ë‹µì„ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸
        accumulated_tool: ëˆ„ì ëœ ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸
    """
    accumulated_text = []
    accumulated_tool = []

    def callback_func(message: dict):
        nonlocal accumulated_text, accumulated_tool
        message_content = message.get("content", None)

        if isinstance(message_content, AIMessageChunk):
            content = message_content.content
            # ì½˜í…ì¸ ê°€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¸ ê²½ìš° (Claude ëª¨ë¸ ë“±ì—ì„œ ì£¼ë¡œ ë°œìƒ)
            if isinstance(content, list) and len(content) > 0:
                message_chunk = content[0]
                # í…ìŠ¤íŠ¸ íƒ€ì…ì¸ ê²½ìš° ì²˜ë¦¬
                if message_chunk["type"] == "text":
                    accumulated_text.append(message_chunk["text"])
                    text_placeholder.markdown("".join(accumulated_text))
                # ë„êµ¬ ì‚¬ìš© íƒ€ì…ì¸ ê²½ìš° ì²˜ë¦¬
                elif message_chunk["type"] == "tool_use":
                    if "partial_json" in message_chunk:
                        accumulated_tool.append(message_chunk["partial_json"])
                    else:
                        tool_call_chunks = message_content.tool_call_chunks
                        tool_call_chunk = tool_call_chunks[0]
                        accumulated_tool.append(
                            "\n```json\n" + str(tool_call_chunk) + "\n```\n"
                        )
                    with tool_placeholder.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=True):
                        st.markdown("".join(accumulated_tool))
            # tool_calls ì†ì„±ì´ ìˆëŠ” ê²½ìš° ì²˜ë¦¬ (OpenAI ëª¨ë¸ ë“±ì—ì„œ ì£¼ë¡œ ë°œìƒ)
            elif (
                hasattr(message_content, "tool_calls")
                and message_content.tool_calls
                and len(message_content.tool_calls[0]["name"]) > 0
            ):
                tool_call_info = message_content.tool_calls[0]
                accumulated_tool.append("\n```json\n" + str(tool_call_info) + "\n```\n")
                with tool_placeholder.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=True):
                    st.markdown("".join(accumulated_tool))
            # ë‹¨ìˆœ ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬
            elif isinstance(content, str):
                accumulated_text.append(content)
                text_placeholder.markdown("".join(accumulated_text))
            # ìœ íš¨í•˜ì§€ ì•Šì€ ë„êµ¬ í˜¸ì¶œ ì •ë³´ê°€ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
            elif (
                hasattr(message_content, "invalid_tool_calls")
                and message_content.invalid_tool_calls
            ):
                tool_call_info = message_content.invalid_tool_calls[0]
                accumulated_tool.append("\n```json\n" + str(tool_call_info) + "\n```\n")
                with tool_placeholder.expander(
                    "ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´ (ìœ íš¨í•˜ì§€ ì•ŠìŒ)", expanded=True
                ):
                    st.markdown("".join(accumulated_tool))
            # tool_call_chunks ì†ì„±ì´ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
            elif (
                hasattr(message_content, "tool_call_chunks")
                and message_content.tool_call_chunks
            ):
                tool_call_chunk = message_content.tool_call_chunks[0]
                accumulated_tool.append(
                    "\n```json\n" + str(tool_call_chunk) + "\n```\n"
                )
                with tool_placeholder.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=True):
                    st.markdown("".join(accumulated_tool))
            # additional_kwargsì— tool_callsê°€ ìˆëŠ” ê²½ìš° ì²˜ë¦¬ (ë‹¤ì–‘í•œ ëª¨ë¸ í˜¸í™˜ì„± ì§€ì›)
            elif (
                hasattr(message_content, "additional_kwargs")
                and "tool_calls" in message_content.additional_kwargs
            ):
                tool_call_info = message_content.additional_kwargs["tool_calls"][0]
                accumulated_tool.append("\n```json\n" + str(tool_call_info) + "\n```\n")
                with tool_placeholder.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=True):
                    st.markdown("".join(accumulated_tool))
        # ë„êµ¬ ë©”ì‹œì§€ì¸ ê²½ìš° ì²˜ë¦¬ (ë„êµ¬ì˜ ì‘ë‹µ)
        elif isinstance(message_content, ToolMessage):
            accumulated_tool.append(
                "\n```json\n" + str(message_content.content) + "\n```\n"
            )
            with tool_placeholder.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=True):
                st.markdown("".join(accumulated_tool))
        return None

    return callback_func, accumulated_text, accumulated_tool


async def process_query(query, text_placeholder, tool_placeholder, timeout_seconds=60):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

    ì´ í•¨ìˆ˜ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì—ì´ì „íŠ¸ì— ì „ë‹¬í•˜ê³ , ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤.
    ì§€ì •ëœ ì‹œê°„ ë‚´ì— ì‘ë‹µì´ ì™„ë£Œë˜ì§€ ì•Šìœ¼ë©´ íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        query: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ í…ìŠ¤íŠ¸
        text_placeholder: í…ìŠ¤íŠ¸ ì‘ë‹µì„ í‘œì‹œí•  Streamlit ì»´í¬ë„ŒíŠ¸
        tool_placeholder: ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ í‘œì‹œí•  Streamlit ì»´í¬ë„ŒíŠ¸
        timeout_seconds: ì‘ë‹µ ìƒì„± ì œí•œ ì‹œê°„(ì´ˆ)

    ë°˜í™˜ê°’:
        response: ì—ì´ì „íŠ¸ì˜ ì‘ë‹µ ê°ì²´
        final_text: ìµœì¢… í…ìŠ¤íŠ¸ ì‘ë‹µ
        final_tool: ìµœì¢… ë„êµ¬ í˜¸ì¶œ ì •ë³´
    """
    try:
        if st.session_state.agent:
            streaming_callback, accumulated_text_obj, accumulated_tool_obj = (
                get_streaming_callback(text_placeholder, tool_placeholder)
            )
            try:
                response = await asyncio.wait_for(
                    astream_graph(
                        st.session_state.agent,
                        {"messages": [HumanMessage(content=query)]},
                        callback=streaming_callback,
                        config=RunnableConfig(
                            recursion_limit=RECURSION_LIMIT,
                            thread_id=st.session_state.thread_id,
                        ),
                    ),
                    timeout=timeout_seconds,
                )
            except asyncio.TimeoutError:
                error_msg = f"â±ï¸ ìš”ì²­ ì‹œê°„ì´ {timeout_seconds}ì´ˆë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
                return {"error": error_msg}, error_msg, ""

            final_text = "".join(accumulated_text_obj)
            final_tool = "".join(accumulated_tool_obj)
            return response, final_text, final_tool
        else:
            return (
                {"error": "ğŸš« ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."},
                "ğŸš« ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "",
            )
    except Exception as e:
        import traceback

        error_msg = f"âŒ ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n{traceback.format_exc()}"
        return {"error": error_msg}, error_msg, ""


async def initialize_session(mcp_config=None):
    """
    MCP ì„¸ì…˜ê³¼ ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        mcp_config: MCP ë„êµ¬ ì„¤ì • ì •ë³´(JSON). Noneì¸ ê²½ìš° ê¸°ë³¸ ì„¤ì • ì‚¬ìš©

    ë°˜í™˜ê°’:
        bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
    """
    with st.spinner("ğŸ”„ MCP ì„œë²„ ë° AI ëª¨ë¸ ì´ˆê¸°í™” ì¤‘..."):
        # ë¨¼ì € ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ì •ë¦¬
        await cleanup_mcp_client()

        if mcp_config is None:
            # config.json íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œ
            mcp_config = load_config_from_json()

        try:
            # 1. ì„ íƒëœ ëª¨ë¸ ê²€ì¦
            selected_model_key = st.session_state.selected_model

            if ":" not in selected_model_key:
                st.error("âŒ ì˜ëª»ëœ ëª¨ë¸ í˜•ì‹ì…ë‹ˆë‹¤. ì œê³µìë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                return False

            provider_name = selected_model_key.split(":")[0]

            # ì œê³µìê°€ ë“±ë¡ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if not st.session_state.model_manager.is_provider_registered(provider_name):
                provider_display = (
                    "OpenAI" if provider_name == "openai" else "AWS Bedrock"
                )
                st.error(
                    f"âŒ {provider_display} ì œê³µìê°€ ë“±ë¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨ë¸ ì„¤ì • íƒ­ì—ì„œ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
                )
                return False

            # 2. MCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            st.info("ğŸ”— MCP ì„œë²„ì— ì—°ê²° ì¤‘...")
            client = MultiServerMCPClient(mcp_config)
            tools = await client.get_tools()
            st.session_state.tool_count = len(tools)
            st.session_state.mcp_client = client

            # 3. ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            st.info(f"ğŸ¤– {selected_model_key} ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
            try:
                model = st.session_state.model_manager.create_model(
                    model_key=selected_model_key, temperature=0.1
                )
            except ModelProviderError as e:
                st.error(str(e))
                return False
            except Exception as e:
                # ì œê³µìë³„ êµ¬ì²´ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€
                if provider_name == "bedrock":
                    if "credentials" in str(e).lower():
                        st.error(
                            "âŒ AWS Bedrock ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                        )
                    elif "region" in str(e).lower():
                        st.error(
                            "âŒ AWS ë¦¬ì „ ì„¤ì •ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. us-east-1 ë¦¬ì „ì„ ì‚¬ìš©í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
                        )
                    else:
                        st.error(f"âŒ AWS Bedrock ëª¨ë¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                elif provider_name == "openai":
                    if "api_key" in str(e).lower() or "unauthorized" in str(e).lower():
                        st.error(
                            "âŒ OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í‚¤ë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                        )
                    else:
                        st.error(f"âŒ OpenAI ëª¨ë¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                else:
                    st.error(f"âŒ ëª¨ë¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                return False

            # 4. LangGraph ì—ì´ì „íŠ¸ ìƒì„±
            st.info("ğŸ”§ AI ì—ì´ì „íŠ¸ êµ¬ì„± ì¤‘...")
            try:
                agent = create_react_agent(
                    model,
                    tools,
                    checkpointer=MemorySaver(),
                    prompt=SYSTEM_PROMPT,
                )
                st.session_state.agent = agent
                st.session_state.session_initialized = True

                # ì„±ê³µ ë©”ì‹œì§€
                model_info = st.session_state.model_manager.get_model_info(
                    selected_model_key
                )
                if model_info:
                    st.success(
                        f"âœ… {model_info.display_name} ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!"
                    )
                else:
                    st.success("âœ… AI ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")

                return True

            except Exception as e:
                st.error(f"âŒ AI ì—ì´ì „íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                return False

        except Exception as e:
            st.error(f"âŒ ì´ˆê¸°í™” ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False


# --- ëª¨ë¸ ì„¤ì • íƒ­ ---
with model_container:
    st.subheader("ğŸ¤– AI ëª¨ë¸ ì„¤ì •")

    # ì•ˆë‚´ë¬¸ ì¶”ê°€
    st.info(
        "ğŸ’¡ **ì•ˆë‚´:** ì•„ë˜ ë‘ ì œê³µì ì¤‘ í•˜ë‚˜ë§Œ ì„¤ì •í•´ë„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‘˜ ë‹¤ ì„¤ì •í•˜ë©´ ëª¨ë¸ì„ ììœ ë¡­ê²Œ ì „í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "openai_api_key" not in st.session_state:
        st.session_state.openai_api_key = ""
    if "bedrock_api_key" not in st.session_state:
        st.session_state.bedrock_api_key = ""

    # AWS Bedrock API í‚¤ ì„¤ì • ì„¹ì…˜ (ìœ„ë¡œ ì´ë™)
    st.markdown("### â˜ï¸ AWS Bedrock API í‚¤ ì„¤ì •")

    bedrock_api_key_input = st.text_input(
        "AWS Bedrock API í‚¤",
        value="",
        type="password",
        help="AWS Bedrock API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”. Cross Region Inferenceë¥¼ ìœ„í•´ us-east-1 ë¦¬ì „ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        placeholder="bedrock-api-key-...",
        key="bedrock_api_key_input",
    )

    col1, col2 = st.columns([3, 1])
    with col2:
        if st.button(
            "â˜ï¸ Bedrock í‚¤ ì ìš©", key="apply_bedrock_key", use_container_width=True
        ):
            if bedrock_api_key_input.strip():
                if st.session_state.model_manager.register_provider(
                    "bedrock", bedrock_api_key_input.strip()
                ):
                    st.session_state.bedrock_api_key = bedrock_api_key_input.strip()
                    st.success("âœ… AWS Bedrock API í‚¤ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()
                else:
                    st.error("âŒ ìœ íš¨í•˜ì§€ ì•Šì€ AWS Bedrock API í‚¤ì…ë‹ˆë‹¤.")
            else:
                st.error("âŒ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    # Bedrock ìƒíƒœ í‘œì‹œ
    if st.session_state.model_manager.is_provider_registered("bedrock"):
        masked_key = (
            st.session_state.bedrock_api_key[:7]
            + "..."
            + st.session_state.bedrock_api_key[-4:]
            if len(st.session_state.bedrock_api_key) > 11
            else "ì„¤ì •ë¨"
        )
        st.success(f"âœ… AWS Bedrock API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ({masked_key})")
        st.info("ğŸŒ Cross Region Inference í™œì„±í™” (us-east-1 ë¦¬ì „)")
    else:
        st.warning("âš ï¸ AWS Bedrock API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    st.divider()

    # OpenAI API í‚¤ ì„¤ì • ì„¹ì…˜ (ì•„ë˜ë¡œ ì´ë™)
    st.markdown("### ğŸ¤– OpenAI API í‚¤ ì„¤ì •")

    openai_api_key_input = st.text_input(
        "OpenAI API í‚¤",
        value="",
        type="password",
        help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”. sk-ë¡œ ì‹œì‘í•˜ëŠ” í‚¤ì…ë‹ˆë‹¤.",
        placeholder="sk-proj-...",
        key="openai_api_key_input",
    )

    col1, col2 = st.columns([3, 1])
    with col2:
        if st.button(
            "ğŸ¤– OpenAI í‚¤ ì ìš©", key="apply_openai_key", use_container_width=True
        ):
            if openai_api_key_input.strip():
                if st.session_state.model_manager.register_provider(
                    "openai", openai_api_key_input.strip()
                ):
                    st.session_state.openai_api_key = openai_api_key_input.strip()
                    st.success("âœ… OpenAI API í‚¤ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()
                else:
                    st.error("âŒ ìœ íš¨í•˜ì§€ ì•Šì€ OpenAI API í‚¤ì…ë‹ˆë‹¤.")
            else:
                st.error("âŒ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    # OpenAI ìƒíƒœ í‘œì‹œ
    if st.session_state.model_manager.is_provider_registered("openai"):
        masked_key = (
            st.session_state.openai_api_key[:7]
            + "..."
            + st.session_state.openai_api_key[-4:]
            if len(st.session_state.openai_api_key) > 11
            else "ì„¤ì •ë¨"
        )
        st.success(f"âœ… OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ({masked_key})")
    else:
        st.warning("âš ï¸ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    st.divider()

    # í†µí•© ëª¨ë¸ ì„ íƒ ì„¹ì…˜
    st.markdown("### ğŸ§  ëª¨ë¸ ì„ íƒ")

    available_models = st.session_state.model_manager.get_available_models()

    if available_models:
        # ëª¨ë¸ ì„ íƒ ë“œë¡­ë‹¤ìš´
        model_options = [model["key"] for model in available_models]

        # í˜„ì¬ ì„ íƒëœ ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
        current_selection = st.session_state.selected_model
        if current_selection not in model_options and model_options:
            current_selection = model_options[0]
            st.session_state.selected_model = current_selection

        def format_model_display(model_key):
            model_info = next(
                (m for m in available_models if m["key"] == model_key), None
            )
            if model_info:
                provider_badge = "ğŸ¤–" if model_info["provider"] == "openai" else "â˜ï¸"
                return f"{provider_badge} {model_info['display']}"
            return model_key

        previous_model = st.session_state.selected_model
        selected_model = st.selectbox(
            "ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ",
            options=model_options,
            index=(
                model_options.index(current_selection)
                if current_selection in model_options
                else 0
            ),
            format_func=format_model_display,
            help="ë“±ë¡ëœ ì œê³µìì˜ ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”.",
            key="model_selector",
        )

        st.session_state.selected_model = selected_model

        # ëª¨ë¸ì´ ë³€ê²½ë˜ì—ˆì„ ë•Œ ì„¸ì…˜ ì´ˆê¸°í™” í•„ìš” ì•Œë¦¼
        if previous_model != selected_model and st.session_state.session_initialized:
            st.warning(
                "âš ï¸ ëª¨ë¸ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤. MCP ë„êµ¬ íƒ­ì—ì„œ 'ì„¤ì • ì ìš©í•˜ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ ë³€ê²½ì‚¬í•­ì„ ì ìš©í•˜ì„¸ìš”."
            )

        st.divider()

        # ì„ íƒëœ ëª¨ë¸ ì •ë³´ í‘œì‹œ
        st.subheader("ğŸ“Š í˜„ì¬ ëª¨ë¸ ì •ë³´")
        model_config = st.session_state.model_manager.get_model_info(selected_model)

        if model_config:
            provider_name = selected_model.split(":")[0]
            provider_info = st.session_state.model_manager.get_provider_info(
                provider_name
            )

            st.write(f"ğŸ§  **ì„ íƒëœ ëª¨ë¸:** {model_config.display_name}")
            st.write(f"ğŸ¢ **ì œê³µì:** {provider_info['display_name']}")
            if model_config.description:
                st.info(f"ğŸ“ {model_config.description}")
    else:
        st.warning("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")

        # ì œê³µì ìƒíƒœ ìš”ì•½ í‘œì‹œ
        st.markdown("### ğŸ“‹ ì œê³µì ìƒíƒœ")
        providers_info = st.session_state.model_manager.get_all_providers_info()

        for provider_name, info in providers_info.items():
            status_icon = "âœ…" if info["is_registered"] else "âŒ"
            st.write(
                f"{status_icon} **{info['display_name']}**: {'ë“±ë¡ë¨' if info['is_registered'] else 'ë¯¸ë“±ë¡'}"
            )
            if info["description"]:
                st.caption(f"   {info['description']}")

# --- MCP ë„êµ¬ ì„¤ì • íƒ­ ---
with mcp_container:
    # ì„¤ì • ì ìš©í•˜ê¸° ë²„íŠ¼ì„ ìµœìƒë‹¨ìœ¼ë¡œ ì´ë™
    if st.button(
        "âš™ï¸ ì„¤ì • ì ìš©í•˜ê¸°",
        key="apply_button",
        type="primary",
        use_container_width=True,
    ):
        # ì ìš© ì¤‘ ë©”ì‹œì§€ í‘œì‹œ
        apply_status = st.empty()
        with apply_status.container():
            st.warning("ğŸ”„ ë³€ê²½ì‚¬í•­ì„ ì ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
            progress_bar = st.progress(0)

            # ì„¤ì • ì €ì¥
            st.session_state.mcp_config_text = json.dumps(
                st.session_state.pending_mcp_config, indent=2, ensure_ascii=False
            )

            # config.json íŒŒì¼ì— ì„¤ì • ì €ì¥
            save_result = save_config_to_json(st.session_state.pending_mcp_config)
            if not save_result:
                st.error("âŒ ì„¤ì • íŒŒì¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

            progress_bar.progress(15)

            # ì„¸ì…˜ ì´ˆê¸°í™” ì¤€ë¹„
            st.session_state.session_initialized = False
            st.session_state.agent = None

            # ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
            progress_bar.progress(30)

            # ì´ˆê¸°í™” ì‹¤í–‰
            success = st.session_state.event_loop.run_until_complete(
                initialize_session(st.session_state.pending_mcp_config)
            )

            # ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
            progress_bar.progress(100)

            if success:
                st.success("âœ… ìƒˆë¡œìš´ ì„¤ì •ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
                # ë„êµ¬ ì¶”ê°€ expander ì ‘ê¸°
                if "mcp_tools_expander" in st.session_state:
                    st.session_state.mcp_tools_expander = False
            else:
                st.error("âŒ ì„¤ì • ì ìš©ì— ì‹¤íŒ¨í•˜ì˜€ìŠµë‹ˆë‹¤.")

        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
        st.rerun()

    st.divider()

    # MCP ë„êµ¬ ìˆ˜ ì •ë³´ í‘œì‹œ
    col1, col2 = st.columns([1, 1])
    with col1:
        st.metric("ğŸ› ï¸ ë“±ë¡ëœ MCP ë„êµ¬", st.session_state.get("tool_count", 0))
    with col2:
        st.metric(
            "âœ… ì´ˆê¸°í™” ìƒíƒœ",
            "ì™„ë£Œ" if st.session_state.get("session_initialized", False) else "ë¯¸ì™„ë£Œ",
        )

    st.divider()

    # í˜„ì¬ ì ìš©ëœ MCP ì„œë²„ ë¦¬ìŠ¤íŠ¸
    st.markdown("### ğŸ“‹ í˜„ì¬ ì ìš©ëœ MCP ì„œë²„")

    # pending configê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ mcp_config_text ê¸°ë°˜ìœ¼ë¡œ ìƒì„±
    if "pending_mcp_config" not in st.session_state:
        try:
            loaded_config = load_config_from_json()
            st.session_state.pending_mcp_config = loaded_config
        except Exception as e:
            st.error(f"ì´ˆê¸° pending config ì„¤ì • ì‹¤íŒ¨: {e}")
            st.session_state.pending_mcp_config = {}

    try:
        pending_config = st.session_state.pending_mcp_config
        if pending_config:
            for i, (tool_name, tool_config) in enumerate(pending_config.items()):
                with st.container():
                    col1, col2 = st.columns([4, 1])
                    with col1:
                        st.markdown(f"**{tool_name}**")
                        if "command" in tool_config:
                            st.caption(
                                f"Command: {tool_config['command']} {' '.join(tool_config.get('args', [])[:2])}..."
                            )
                        elif "url" in tool_config:
                            st.caption(f"URL: {tool_config['url']}")
                    with col2:
                        # ê³ ìœ í•œ í‚¤ ìƒì„±: ë„êµ¬ ì´ë¦„ê³¼ ì¸ë±ìŠ¤ ì¡°í•©
                        if st.button(
                            "ğŸ—‘ï¸", key=f"delete_server_{tool_name}_{i}", help="ì‚­ì œ"
                        ):
                            del st.session_state.pending_mcp_config[tool_name]
                            st.success(f"{tool_name} ì„œë²„ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.rerun()

                    if i < len(pending_config) - 1:
                        st.divider()
        else:
            st.info("ë“±ë¡ëœ MCP ì„œë²„ê°€ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error("MCP ì„œë²„ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    st.divider()

    # MCP ì„œë²„ ì¶”ê°€ ì„¹ì…˜
    st.markdown("### â• ìƒˆ MCP ì„œë²„ ì¶”ê°€")
    st.markdown("ğŸ’¡ ì¤‘ê´„í˜¸ ìˆ«ìë¥¼ ì˜ í™•ì¸í•˜ê³  JSON í˜•ì‹ì„ ì²´í¬í•´ì£¼ì„¸ìš”")

    # ê¸°ë³¸ ì˜ˆì‹œ JSON
    default_json = {
        "desktop-commander": {
            "command": "npx",
            "args": [
                "-y",
                "@smithery/cli@latest",
                "run",
                "@wonderwhy-er/desktop-commander",
                "--key",
                "8f1bc671-fe10-43cd-8da1-b76a057f3c0a",
            ],
            "transport": "stdio",
        }
    }

    default_text = json.dumps(default_json, indent=2, ensure_ascii=False)

    new_tool_json = st.text_area(
        "MCP ì„œë²„ ì„¤ì • (JSON)",
        default_text,
        height=300,
        help="JSON í˜•ì‹ìœ¼ë¡œ MCP ì„œë²„ ì„¤ì •ì„ ì…ë ¥í•˜ì„¸ìš”",
    )

    # ì¶”ê°€í•˜ê¸° ë²„íŠ¼
    if st.button(
        "â• MCP ì„œë²„ ì¶”ê°€",
        type="primary",
        key="add_mcp_server_button",
        use_container_width=True,
    ):
        try:
            # ì…ë ¥ê°’ ê²€ì¦
            if not new_tool_json.strip().startswith(
                "{"
            ) or not new_tool_json.strip().endswith("}"):
                st.error("JSONì€ ì¤‘ê´„í˜¸({})ë¡œ ì‹œì‘í•˜ê³  ëë‚˜ì•¼ í•©ë‹ˆë‹¤.")
                st.markdown('ì˜¬ë°”ë¥¸ í˜•ì‹: `{ "ë„êµ¬ì´ë¦„": { ... } }`')
            else:
                # JSON íŒŒì‹±
                parsed_tool = json.loads(new_tool_json)

                # mcpServers í˜•ì‹ì¸ì§€ í™•ì¸í•˜ê³  ì²˜ë¦¬
                if "mcpServers" in parsed_tool:
                    # mcpServers ì•ˆì˜ ë‚´ìš©ì„ ìµœìƒìœ„ë¡œ ì´ë™
                    parsed_tool = parsed_tool["mcpServers"]
                    st.info("'mcpServers' í˜•ì‹ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")

                # ì…ë ¥ëœ ë„êµ¬ ìˆ˜ í™•ì¸
                if len(parsed_tool) == 0:
                    st.error("ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ ë„êµ¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    # ëª¨ë“  ë„êµ¬ì— ëŒ€í•´ ì²˜ë¦¬
                    success_tools = []
                    for tool_name, tool_config in parsed_tool.items():
                        # URL í•„ë“œ í™•ì¸ ë° transport ì„¤ì •
                        if "url" in tool_config:
                            # URLì´ ìˆëŠ” ê²½ìš° transportë¥¼ "sse"ë¡œ ì„¤ì •
                            tool_config["transport"] = "sse"
                            st.info(
                                f"'{tool_name}' ë„êµ¬ì— URLì´ ê°ì§€ë˜ì–´ transportë¥¼ 'sse'ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤."
                            )
                        elif "transport" not in tool_config:
                            # URLì´ ì—†ê³  transportë„ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ "stdio" ì„¤ì •
                            tool_config["transport"] = "stdio"

                        # í•„ìˆ˜ í•„ë“œ í™•ì¸
                        if "command" not in tool_config and "url" not in tool_config:
                            st.error(
                                f"'{tool_name}' ë„êµ¬ ì„¤ì •ì—ëŠ” 'command' ë˜ëŠ” 'url' í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤."
                            )
                        elif "command" in tool_config and "args" not in tool_config:
                            st.error(
                                f"'{tool_name}' ë„êµ¬ ì„¤ì •ì—ëŠ” 'args' í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤."
                            )
                        elif "command" in tool_config and not isinstance(
                            tool_config["args"], list
                        ):
                            st.error(
                                f"'{tool_name}' ë„êµ¬ì˜ 'args' í•„ë“œëŠ” ë°˜ë“œì‹œ ë°°ì—´([]) í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
                            )
                        else:
                            # pending_mcp_configì— ë„êµ¬ ì¶”ê°€
                            st.session_state.pending_mcp_config[tool_name] = tool_config
                            success_tools.append(tool_name)

                    # ì„±ê³µ ë©”ì‹œì§€
                    if success_tools:
                        if len(success_tools) == 1:
                            st.success(
                                f"{success_tools[0]} ë„êµ¬ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. ì ìš©í•˜ë ¤ë©´ 'ì„¤ì • ì ìš©í•˜ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
                            )
                        else:
                            tool_names = ", ".join(success_tools)
                            st.success(
                                f"ì´ {len(success_tools)}ê°œ ë„êµ¬({tool_names})ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. ì ìš©í•˜ë ¤ë©´ 'ì„¤ì • ì ìš©í•˜ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
                            )
                        # ì¶”ê°€ë˜ë©´ expanderë¥¼ ì ‘ì–´ì¤Œ
                        st.session_state.mcp_tools_expander = False
                        st.rerun()
        except json.JSONDecodeError as e:
            st.error(f"JSON íŒŒì‹± ì—ëŸ¬: {e}")
            st.markdown(
                f"""
                **ìˆ˜ì • ë°©ë²•**:
                1. JSON í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.
                2. ëª¨ë“  í‚¤ëŠ” í°ë”°ì˜´í‘œ(")ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤.
                3. ë¬¸ìì—´ ê°’ë„ í°ë”°ì˜´í‘œ(")ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤.
                4. ë¬¸ìì—´ ë‚´ì—ì„œ í°ë”°ì˜´í‘œë¥¼ ì‚¬ìš©í•  ê²½ìš° ì´ìŠ¤ì¼€ì´í”„(\\")í•´ì•¼ í•©ë‹ˆë‹¤.
                """
            )
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

    st.divider()

    # ê¸°ë³¸ ì„œë²„ ë³µì› ë²„íŠ¼
    if st.button(
        "ğŸ”„ ê¸°ë³¸ ì„œë²„ ë³µì› (ì‹œê°„, í—¬ìŠ¤ê³„ì‚°ê¸°)",
        key="restore_default_mcp_tools",
        use_container_width=True,
    ):
        # ê¸°ë³¸ ì„¤ì • ì •ì˜
        default_tools = {
            "get_current_time": {
                "command": "python",
                "args": ["./mcp_servers/time.py"],
                "transport": "stdio",
            },
            "fitness_calculator": {
                "command": "python",
                "args": ["./mcp_servers/fitness.py"],
                "transport": "stdio",
            },
        }

        # ê¸°ì¡´ì— ì—†ëŠ” ê¸°ë³¸ ë„êµ¬ë§Œ ì¶”ê°€
        added_tools = []
        for tool_name, tool_config in default_tools.items():
            if tool_name not in st.session_state.pending_mcp_config:
                st.session_state.pending_mcp_config[tool_name] = tool_config
                added_tools.append(tool_name)

        if added_tools:
            tool_names = ", ".join(added_tools)
            st.success(f"ê¸°ë³¸ ì„œë²„ {tool_names}ê°€ ë³µì›ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.rerun()
        else:
            st.info("ëª¨ë“  ê¸°ë³¸ ì„œë²„ê°€ ì´ë¯¸ ë“±ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

    st.divider()  # êµ¬ë¶„ì„  ì¶”ê°€


# --- ì±—ë´‡ íƒ­ ---
with chat_container:
    # ìƒë‹¨ ë²„íŠ¼ ì˜ì—­
    col1, col2 = st.columns([3, 1])

    with col1:
        # --- ì œê³µì ë° ì„¸ì…˜ ìƒíƒœ í™•ì¸ ---
        available_models = st.session_state.model_manager.get_available_models()

        if not available_models:
            st.warning(
                "âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. 'ëª¨ë¸ ì„¤ì •' íƒ­ì—ì„œ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
            )
        elif not st.session_state.session_initialized:
            st.info(
                "MCP ì„œë²„ì™€ ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'MCP ë„êµ¬' íƒ­ì—ì„œ 'ì„¤ì • ì ìš©í•˜ê¸°' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”."
            )

    with col2:
        # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
        if st.button(
            "ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", key="reset_chat_history", use_container_width=True
        ):
            # thread_id ì´ˆê¸°í™”
            st.session_state.thread_id = random_uuid()
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
            st.session_state.history = []
            # ì•Œë¦¼ ë©”ì‹œì§€
            st.success("âœ… ëŒ€í™”ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
            st.rerun()

    st.divider()

    # --- ëŒ€í™” ê¸°ë¡ ì¶œë ¥ ---
    print_message()

# --- í™”ë©´ í•˜ë‹¨ ê³ ì •: ì‚¬ìš©ì ì…ë ¥ ë° ì²˜ë¦¬ ---
user_query = st.chat_input("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
if user_query:
    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
    available_models = st.session_state.model_manager.get_available_models()
    if not available_models:
        st.warning(
            "âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. 'ëª¨ë¸ ì„¤ì •' íƒ­ì—ì„œ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        )
    elif st.session_state.session_initialized:
        # ì±—ë´‡ íƒ­ì´ í™œì„±í™”ë˜ì–´ ìˆì„ ë•Œë§Œ ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
        with chat_container:
            st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»").markdown(user_query)
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                tool_placeholder = st.empty()
                text_placeholder = st.empty()
                resp, final_text, final_tool = (
                    st.session_state.event_loop.run_until_complete(
                        process_query(
                            user_query,
                            text_placeholder,
                            tool_placeholder,
                            TIMEOUT_SECONDS,
                        )
                    )
                )
            if "error" in resp:
                st.error(resp["error"])
            else:
                st.session_state.history.append({"role": "user", "content": user_query})
                st.session_state.history.append(
                    {"role": "assistant", "content": final_text}
                )
                if final_tool.strip():
                    st.session_state.history.append(
                        {"role": "assistant_tool", "content": final_tool}
                    )
                st.rerun()
    else:
        st.warning(
            "âš ï¸ MCP ì„œë²„ì™€ ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'MCP ë„êµ¬' íƒ­ì—ì„œ 'ì„¤ì • ì ìš©í•˜ê¸°' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”."
        )
